{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "J-SOCfgJtHJw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from enum import IntEnum\n",
        "from copy import deepcopy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "#plt.style.use('seaborn-notebook')\n",
        "sns.set_theme(context='notebook')\n",
        "sns.set_style(\"whitegrid\")\n",
        "import matplotlib.colors as mcolors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "s0cEpP6BtPSO"
      },
      "outputs": [],
      "source": [
        "class Action(IntEnum):\n",
        "    up = 0\n",
        "    right = 1\n",
        "    down = 2\n",
        "    left = 3\n",
        "\n",
        "action_to_str = {\n",
        "    Action.up : \"up\",\n",
        "    Action.right : \"right\",\n",
        "    Action.down : \"down\",\n",
        "    Action.left : \"left\",\n",
        "}\n",
        "\n",
        "action_to_offset = {\n",
        "    Action.up : (-1, 0),\n",
        "    Action.right : (0, 1),\n",
        "    Action.down : (1, 0),\n",
        "    Action.left : (0, -1),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvTUR66UtPUk"
      },
      "outputs": [],
      "source": [
        "class GridWorld:\n",
        "\n",
        "    def __init__(self, height, width, goal, goal_value=5.0, danger=[], danger_value=-5.0, blocked=[], noise=0.0):\n",
        "        \"\"\"\n",
        "        Initialize the GridWorld environment.\n",
        "        Creates a gridworld like MDP\n",
        "         - height (int): Number of rows\n",
        "         - width (int): Number of columns\n",
        "         - goal (int): Index number of goal cell\n",
        "         - goal_value (float): Reward given for goal cell\n",
        "         - danger (list of int): Indices of cells marked as danger\n",
        "         - danger_value (float): Reward given for danger cell\n",
        "         - blocked (list of int): Indices of cells marked as blocked (can't enter)\n",
        "         - noise (float): probability of resulting state not being what was expected\n",
        "        \"\"\"\n",
        "\n",
        "        self._width = width\n",
        "        self._height = height\n",
        "        self._grid_values = [0 for _ in range(height * width)] # Initialize state values.\n",
        "        self._goal_value = goal_value\n",
        "        self._danger_value = danger_value\n",
        "        self._goal_cell = goal\n",
        "        self._danger_cells = danger\n",
        "        self._blocked_cells = blocked\n",
        "        self._noise = noise # Noise level in the environment.\n",
        "        assert noise >= 0 and noise < 1 # Ensure valid noise value.\n",
        "        self.create_next_values() # Initialize the next state values.\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reset the state values to their initial state.\n",
        "        \"\"\"\n",
        "        self._grid_values = [0 for _ in range(self._height * self._width)]\n",
        "        self.create_next_values()\n",
        "\n",
        "\n",
        "    def _inbounds(self, state):\n",
        "        \"\"\"\n",
        "        Check if a state index is within the grid boundaries.\n",
        "        \"\"\"\n",
        "        return state >= 0 and state < self._width * self._height\n",
        "\n",
        "    def _inbounds_rc(self, state_r, state_c):\n",
        "        \"\"\"\n",
        "        Check if row and column indices are within the grid boundaries.\n",
        "        \"\"\"\n",
        "        return state_r >= 0 and state_r < self._height and state_c >= 0 and state_c < self._width\n",
        "\n",
        "    def _state_to_rc(self, state):\n",
        "        \"\"\"\n",
        "        Convert a state index to row and column indices.\n",
        "        \"\"\"\n",
        "        return state // self._width, state % self._width\n",
        "\n",
        "    def _state_from_action(self, state, action):\n",
        "        \"\"\"\n",
        "        Gets the state as a result of applying the given action\n",
        "        \"\"\"\n",
        "        row, col = self._state_to_rc(state)\n",
        "        dir_row, dir_col = action_to_offset[action] # returns the directional offset\n",
        "\n",
        "        new_row = row + dir_row\n",
        "        new_col = col + dir_col\n",
        "\n",
        "        if not self._inbounds_rc(new_row, new_col):\n",
        "            return state  # bump into wall â†’ stay in place\n",
        "\n",
        "        return new_row * self._width + new_col # convert back into original state form\n",
        "\n",
        "    def is_terminal(self, state):\n",
        "        \"\"\"\n",
        "        Returns true if a state is terminal (goal, or danger)\n",
        "        \"\"\"\n",
        "        return state in self._danger_cells or state == self._goal_cell\n",
        "\n",
        "    def get_states(self):\n",
        "        \"\"\"\n",
        "        Gets all non-terminal states in the environment\n",
        "        \"\"\"\n",
        "        return [x for x in range(self._width*self._height) if x not in self._danger_cells and x != self._goal_cell]\n",
        "\n",
        "\n",
        "    def get_actions(self, state):\n",
        "        \"\"\"\n",
        "        Returns a list of valid actions given the current state\n",
        "        \"\"\"\n",
        "        #Start with a full list, remove actions that lead to illegal states\n",
        "        actions = [Action.up, Action.right, Action.down, Action.left]\n",
        "\n",
        "        state_row, state_col = self._state_to_rc(state) # cconvert state to row,col format\n",
        "        blocked_list = [self._state_to_rc(x) for x in self._blocked_cells]\n",
        "        \n",
        "\n",
        "        # check bounds and illegal states\n",
        "        if (state_row - 1 < 0 or ((state_row-1, state_col) in blocked_list)): # Up\n",
        "            actions.remove(Action.up)\n",
        "\n",
        "        if (state_col + 1 >= self._width or ((state_row, state_col+1) in blocked_list)): # Right\n",
        "            actions.remove(Action.right)\n",
        "\n",
        "        if (state_row + 1 > self._height or ((state_row+1, state_col) in blocked_list)): # Down\n",
        "            actions.remove(Action.down)\n",
        "\n",
        "        if (state_col - 1 < 0 or ((state_row, state_col-1) in blocked_list)): # Left\n",
        "            actions.remove(Action.left)\n",
        "\n",
        "        return actions\n",
        "\n",
        "\n",
        "\n",
        "    def get_reward(self, state):\n",
        "        \"\"\"\n",
        "        Get the reward for being in the current state\n",
        "        \"\"\"\n",
        "        assert self._inbounds(state)\n",
        "        # Reward is non-zero for danger or goal\n",
        "        #TO DO:\n",
        "        if state == self._goal_cell:\n",
        "            return 5\n",
        "        elif state in self._danger_cells:\n",
        "            return -5\n",
        "        \n",
        "        return 0\n",
        "\n",
        "\n",
        "    def get_transitions(self, state, action):\n",
        "        \"\"\"\n",
        "        Get a list of transitions as a result of attempting the action in the current state\n",
        "        Each item in the list is a dictionary, containing the probability of reaching that state and the state itself\n",
        "        \"\"\"\n",
        "        #Assume action input is Action.___\n",
        "        transitions = dict() # start with an empty dict\n",
        "        possible_actions = [Action.up, Action.right, Action.down, Action.left]\n",
        "\n",
        "        # Add the main state/action pair\n",
        "        transitions.update({self._state_from_action(state, action): 1 - self._noise})\n",
        "\n",
        "        for a in possible_actions: # iterate threough all actions\n",
        "            # only if action isnt added yet\n",
        "            next_state = self._state_from_action(state, a)\n",
        "\n",
        "            if next_state not in transitions.keys():\n",
        "                transitions.update({next_state:self._noise/3})# Add the other state and is chance that the noise takes it in that direction\n",
        "            \n",
        "\n",
        "        return transitions\n",
        "\n",
        "\n",
        "    def get_value(self, state):\n",
        "        \"\"\"\n",
        "        Get the current value of the state\n",
        "        \"\"\"\n",
        "        assert self._inbounds(state)\n",
        "        return self._grid_values[state]\n",
        "\n",
        "    def create_next_values(self):\n",
        "        \"\"\"\n",
        "        Creates a temporary storage for state value updating\n",
        "        If this is not used, then asynchronous updating may result in unexpected results\n",
        "        To use properly, run this at the start of each iteration\n",
        "        \"\"\"\n",
        "        self._new_grid_values = deepcopy(self._grid_values) #creates a temp storage value assigned to the GridWorld class\n",
        "\n",
        "    def set_next_values(self):\n",
        "        \"\"\"\n",
        "        Set the state values from the temporary copied values\n",
        "        To use properly, run this at the end of each iteration\n",
        "        \"\"\"\n",
        "        # imagine like a full commit of these new values\n",
        "        self._grid_values = self._new_grid_values\n",
        "        \n",
        "\n",
        "    def set_value(self, state, value):\n",
        "        \"\"\"\n",
        "        Set the value of the state into the temporary copy\n",
        "        This value will not update into main storage until self.set_next_values() is called.\n",
        "        \"\"\"\n",
        "        assert self._inbounds(state) #Ensure we are in bounds and pass in the assigned value\n",
        "        self._new_grid_values[state] = value\n",
        "\n",
        "    def solve_linear_system(self, discount_factor=1.0):\n",
        "        \"\"\"\n",
        "        Solve the gridworld using a system of linear equations.\n",
        "        :param discount_factor: The discount factor for future rewards.\n",
        "        \"\"\"\n",
        "        \n",
        "        states = list(range(self._width*self._height))\n",
        "\n",
        "        #define an empty A and b to be solved\n",
        "        A = np.zeros((len(states), len(states)))\n",
        "        b = np.zeros(len(states))\n",
        "\n",
        "        index = {s: i for i, s in enumerate(states)} # map states to equation indicies\n",
        "\n",
        "        for st in states: # we iterate for every state to form this matrix\n",
        "            i = index[st]\n",
        "            \n",
        "            #blocked states (value is 0)\n",
        "            if st in self._blocked_cells:\n",
        "                A[i,i] = 1\n",
        "                b[i] = 0\n",
        "                continue\n",
        "\n",
        "            # terminal states\n",
        "            if self.is_terminal(st):\n",
        "                A[i,i] = 1\n",
        "                b[i] = self.get_reward(st)\n",
        "                continue\n",
        "\n",
        "            # iterate through all possible actions in a NORMAL state\n",
        "            A[i,i] = 1\n",
        "            b[i] = self.get_reward(st)\n",
        "\n",
        "            for a in self.get_actions(st):\n",
        "                t = self.get_transitions(st,a) # gets the transitions of an action\n",
        "\n",
        "                #iterate through each transition\n",
        "                for next_st, p in t.items():\n",
        "                    if self.is_terminal(next_st): #Is the next state terminal?\n",
        "                        #calculate b\n",
        "                        b[i] += discount_factor * p * self.get_reward(next_st)\n",
        "                    else: # calculate A\n",
        "                        j = index[next_st]\n",
        "                        A[i,j] -= discount_factor * p\n",
        "\n",
        "        # solve the matrix\n",
        "        V = np.linalg.solve(A,b)\n",
        "\n",
        "        for s, i in index.items():\n",
        "            self._grid_values[s] = V[i]\n",
        "\n",
        "        return V\n",
        "    \n",
        "    def __str__(self):\n",
        "        \"\"\"\n",
        "        Pretty print the state values\n",
        "        \"\"\"\n",
        "        out_str = \"\"\n",
        "        for r in range(self._height):\n",
        "            for c in range(self._width):\n",
        "                cell = r * self._width + c\n",
        "                if cell in self._blocked_cells:\n",
        "                    out_str += \"{:>6}\".format(\"----\")\n",
        "                elif cell == self._goal_cell:\n",
        "                    out_str += \"{:>6}\".format(\"GOAL\")\n",
        "                elif cell in self._danger_cells:\n",
        "                    out_str += \"{:>6.2f}\".format(self._danger_value)\n",
        "                else:\n",
        "                    out_str += \"{:>6.2f}\".format(self._grid_values[cell])\n",
        "                out_str += \" \"\n",
        "            out_str += \"\\n\"\n",
        "        return out_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "Dfgo0v5sNO78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-3.92249686 -8.47637202 -5.         -4.75       -0.          4.34742795\n",
            "  0.          0.          0.          4.75        8.49873681  0.\n",
            "  0.          0.          5.          4.5986108   3.96830102  4.57854817\n",
            " -5.         -0.77219166 -7.62639489 -5.          5.85122337  0.72941095\n",
            " -0.81283332]\n"
          ]
        }
      ],
      "source": [
        "# Initialize your GridWorld\n",
        "simple_gw = GridWorld(height=5, width=5, goal=14, danger=[2, 18, 21], blocked=[6, 7, 11, 12], noise=0.0)\n",
        "\n",
        "# Solve the linear system\n",
        "values_grid = simple_gw.solve_linear_system(discount_factor=0.95)\n",
        "print(values_grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "HJI-fizhOIM-"
      },
      "outputs": [],
      "source": [
        "def value_iteration(gw, discount, tolerance=0.1):\n",
        "    #TO DO\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "OwueBZR8tPXE"
      },
      "outputs": [],
      "source": [
        "# Initialize your GridWorld\n",
        "simple_gw = GridWorld(height=5, width=5, goal=14, danger=[2, 18, 21], blocked=[6, 7, 11, 12], noise=0.0)\n",
        "noisy_gw = GridWorld(height=5, width=5, goal=14, danger=[2, 18, 21], blocked=[6, 7, 11, 12], noise=0.2)\n",
        "discount = 0.95\n",
        "tolerance = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "Yli-IAo6tPZU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  0.00   0.00  -5.00   0.00   0.00 \n",
            "  0.00   ----   ----   0.00   0.00 \n",
            "  0.00   ----   ----   0.00   GOAL \n",
            "  0.00   0.00   0.00  -5.00   0.00 \n",
            "  0.00  -5.00   0.00   0.00   0.00 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "value_iteration(simple_gw, discount, 0.1)\n",
        "print(simple_gw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "uUo6u5kutPbm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  0.00   0.00  -5.00   0.00   0.00 \n",
            "  0.00   ----   ----   0.00   0.00 \n",
            "  0.00   ----   ----   0.00   GOAL \n",
            "  0.00   0.00   0.00  -5.00   0.00 \n",
            "  0.00  -5.00   0.00   0.00   0.00 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "value_iteration(noisy_gw, discount, 0.1)\n",
        "print(noisy_gw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "4uXK_mV9tPdp"
      },
      "outputs": [],
      "source": [
        "def policy_iteration(gw, discount, tolerance=0.1):\n",
        "    #TO DO\n",
        "    pass"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
